{"cells":[{"cell_type":"code","id":"initial_id","metadata":{"collapsed":true,"id":"initial_id"},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import GroupKFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n","import math\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings"],"outputs":[],"execution_count":null},{"metadata":{"id":"676747a6f977b0d9"},"cell_type":"code","source":["# Загрузка данных\n","user_features = pd.read_csv('data/user_features.csv')\n","item_features = pd.read_csv('data/item_features.csv')\n","events = pd.read_csv('data/events.csv')"],"id":"676747a6f977b0d9","outputs":[],"execution_count":null},{"metadata":{"id":"2e7be5d69b581ff1"},"cell_type":"code","source":["\n","user_features = pd.get_dummies(user_features, columns=['gender'], drop_first=True)\n","\n","\n","if 'age' in user_features.columns:\n","    scaler_user_age = StandardScaler()\n","    user_features['age'] = scaler_user_age.fit_transform(user_features[['age']])\n","\n","events['datetime'] = pd.to_datetime(events['timestamp'], unit='s')\n","events['hour'] = events['datetime'].dt.hour\n","events['day_of_week'] = events['datetime'].dt.dayofweek\n","\n","\n","events_sorted = events.sort_values(['user_id', 'timestamp'])\n","\n","user_ids = user_features['user_id'].unique()\n","item_ids = item_features['item_id'].unique()\n","\n","user_id_map = {id: idx for idx, id in enumerate(user_ids)}\n","item_id_map = {id: idx for idx, id in enumerate(item_ids)}\n","\n","events_sorted['user_idx'] = events_sorted['user_id'].map(user_id_map)\n","events_sorted['item_idx'] = events_sorted['item_id'].map(item_id_map)\n"],"id":"2e7be5d69b581ff1","outputs":[],"execution_count":null},{"metadata":{"id":"fd9b3c583e90ca53"},"cell_type":"code","source":["\n","user_total_interactions = events_sorted.groupby('user_idx').size().reset_index(name='user_total_interactions')\n","user_features = pd.merge(user_features, user_total_interactions, left_index=True, right_on='user_idx', how='left').fillna(0)\n","user_features['user_total_interactions'] = user_features['user_total_interactions'].astype(int)\n","\n","\n","if 'rating' in events_sorted.columns:\n","    user_avg_rating = events_sorted.groupby('user_idx')['rating'].mean().reset_index(name='user_avg_rating')\n","    user_features = pd.merge(user_features, user_avg_rating, on='user_idx', how='left').fillna(0)\n","\n","\n","genre_columns = [col for col in item_features.columns if 'genre_' in col]\n","user_genres = pd.merge(events_sorted, item_features, on='item_id', how='left')\n","user_genres = user_genres.groupby('user_idx')[genre_columns].sum().reset_index()\n","user_features = pd.merge(user_features, user_genres, on='user_idx', how='left').fillna(0)\n","\n","\n","last_interaction = events_sorted.groupby('user_idx')['datetime'].max().reset_index(name='last_interaction_time')\n","current_time = events_sorted['datetime'].max()\n","last_interaction['days_since_last_interaction'] = (current_time - last_interaction['last_interaction_time']).dt.days\n","user_features = pd.merge(user_features, last_interaction[['user_idx', 'days_since_last_interaction']], on='user_idx', how='left').fillna(0)\n","\n","events_sorted['week'] = events_sorted['datetime'].dt.isocalendar().week\n","user_weekly_interactions = events_sorted.groupby(['user_idx', 'week']).size().reset_index(name='weekly_interactions')\n","user_freq = user_weekly_interactions.groupby('user_idx')['weekly_interactions'].mean().reset_index(name='avg_weekly_interactions')\n","user_features = pd.merge(user_features, user_freq, on='user_idx', how='left').fillna(0)\n","\n","user_continuous_features = ['user_total_interactions', 'user_avg_rating', 'days_since_last_interaction', 'avg_weekly_interactions']\n","scaler_user = StandardScaler()\n","user_features[user_continuous_features] = scaler_user.fit_transform(user_features[user_continuous_features])\n","\n","first_interaction = events_sorted.groupby('user_idx')['datetime'].min().reset_index(name='first_interaction_time')\n","user_features = pd.merge(user_features, first_interaction, on='user_idx', how='left').fillna(current_time)\n","user_features['days_since_first_interaction'] = (current_time - user_features['first_interaction_time']).dt.days\n","user_features = user_features.drop(['first_interaction_time'], axis=1)\n","\n","events_sorted_user = events_sorted.sort_values(['user_idx', 'datetime'])\n","events_sorted_user['prev_datetime'] = events_sorted_user.groupby('user_idx')['datetime'].shift(1)\n","events_sorted_user['time_diff'] = (events_sorted_user['datetime'] - events_sorted_user['prev_datetime']).dt.days\n","user_time_diff = events_sorted_user.groupby('user_idx')['time_diff'].mean().reset_index(name='avg_time_between_interactions')\n","user_features = pd.merge(user_features, user_time_diff, on='user_idx', how='left').fillna(0)\n","\n","additional_user_continuous_features = ['days_since_first_interaction', 'avg_time_between_interactions']\n","user_features[additional_user_continuous_features] = scaler_user.fit_transform(user_features[additional_user_continuous_features])\n"],"id":"fd9b3c583e90ca53","outputs":[],"execution_count":null},{"metadata":{"id":"7c89f09a4e1568c1"},"cell_type":"code","source":["\n","item_total_interactions = events_sorted.groupby('item_idx').size().reset_index(name='item_total_interactions')\n","item_features = pd.merge(item_features, item_total_interactions, left_index=True, right_on='item_idx', how='left').fillna(0)\n","item_features['item_total_interactions'] = item_features['item_total_interactions'].astype(int)\n","\n","if 'rating' in events_sorted.columns:\n","    item_avg_rating = events_sorted.groupby('item_idx')['rating'].mean().reset_index(name='item_avg_rating')\n","    item_features = pd.merge(item_features, item_avg_rating, on='item_idx', how='left').fillna(0)\n","\n","item_features['genre_count'] = item_features[genre_columns].sum(axis=1)\n","\n","recent_threshold = current_time - pd.Timedelta(days=30)\n","recent_items = events_sorted[events_sorted['datetime'] >= recent_threshold].groupby('item_idx').size().reset_index(name='is_recent')\n","recent_items['is_recent'] = 1\n","item_features = pd.merge(item_features, recent_items[['item_idx', 'is_recent']], on='item_idx', how='left').fillna(0)\n","item_features['is_recent'] = item_features['is_recent'].astype(int)\n","\n","item_continuous_features = ['item_total_interactions', 'item_avg_rating', 'genre_count']\n","scaler_item = StandardScaler()\n","item_features[item_continuous_features] = scaler_item.fit_transform(item_features[item_continuous_features])\n"],"id":"7c89f09a4e1568c1","outputs":[],"execution_count":null},{"metadata":{"id":"2d2e8ad5291d130e"},"cell_type":"code","source":["train_user_ids = events_sorted.iloc[:int(0.8 * len(events_sorted))]['user_id'].unique()\n","train_user_indices = [user_id_map[user_id] for user_id in train_user_ids if user_id in user_id_map]\n","\n","\n","X_train_users = user_features.iloc[train_user_indices][user_continuous_features + genre_columns + additional_user_continuous_features].values\n","y_train_users = np.ones(X_train_users.shape[0])\n","\n","rf_user = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","rf_user.fit(X_train_users, y_train_users)\n","\n","selector_user = SelectFromModel(rf_user, prefit=True, threshold='median')\n","X_train_users_selected = selector_user.transform(X_train_users)\n","\n","user_features_selected = selector_user.transform(user_features[user_continuous_features + genre_columns + additional_user_continuous_features].values)\n","\n","train_item_ids = events_sorted.iloc[:int(0.8 * len(events_sorted))]['item_id'].unique()\n","train_item_indices = [item_id_map[item_id] for item_id in train_item_ids if item_id in item_id_map]\n","\n","X_train_items = item_features.iloc[train_item_indices][item_continuous_features].values\n","y_train_items = np.ones(X_train_items.shape[0])\n","\n","rf_item = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","rf_item.fit(X_train_items, y_train_items)\n","\n","selector_item = SelectFromModel(rf_item, prefit=True, threshold='median')\n","X_train_items_selected = selector_item.transform(X_train_items)\n","\n","item_features_selected = selector_item.transform(item_features[item_continuous_features].values)\n","\n"],"id":"2d2e8ad5291d130e","outputs":[],"execution_count":null},{"metadata":{"id":"8a436b99b5053f05"},"cell_type":"code","source":["scaler_user_selected = StandardScaler()\n","user_features_selected = scaler_user_selected.fit_transform(user_features_selected)\n","\n","scaler_item_selected = StandardScaler()\n","item_features_selected = scaler_item_selected.fit_transform(item_features_selected)\n","\n","user_features_tensor = torch.tensor(user_features_selected, dtype=torch.float)\n","item_features_tensor = torch.tensor(item_features_selected, dtype=torch.float)"],"id":"8a436b99b5053f05","outputs":[],"execution_count":null},{"metadata":{"id":"4916117d15eee3d2"},"cell_type":"code","source":["user_sequences = events_sorted.groupby('user_id')['item_id'].apply(list).to_dict()\n","\n","item_encoder = LabelEncoder()\n","all_item_ids = events_sorted['item_id'].unique()\n","item_encoder.fit(all_item_ids)\n","num_items = len(item_encoder.classes_) + 1  # +1 для токена PAD\n","\n","all_X = []\n","all_y = []\n","all_user_ids = []\n","\n","for user_id, seq in user_sequences.items():\n","    encoded_seq = item_encoder.transform(seq) + 1  # +1 для PAD\n","    if len(encoded_seq) < 2:\n","        continue\n","    for i in range(1, len(encoded_seq)):\n","        X_seq = encoded_seq[:i]\n","        y_target = encoded_seq[i]\n","        all_X.append(X_seq)\n","        all_y.append(y_target)\n","        all_user_ids.append(user_id)\n"],"id":"4916117d15eee3d2","outputs":[],"execution_count":null},{"metadata":{"id":"55e6c93d5d5549d7"},"cell_type":"code","source":["max_sequence_length = max(len(seq) for seq in all_X)\n","\n","padded_X = nn.utils.rnn.pad_sequence(\n","    [torch.tensor(seq, dtype=torch.long) for seq in all_X],\n","    batch_first=True,\n","    padding_value=0\n",")\n","\n","X = padded_X\n","y = torch.tensor(all_y, dtype=torch.long)\n","\n","user_ids_list = all_user_ids"],"id":"55e6c93d5d5549d7","outputs":[],"execution_count":null},{"metadata":{"id":"626638afb300d137"},"cell_type":"code","source":["gkf = GroupKFold(n_splits=5)\n","groups = np.array(user_ids_list)\n","\n","for train_idx, val_idx in gkf.split(X, y, groups):\n","    X_train = X[train_idx]\n","    X_val = X[val_idx]\n","    y_train = y[train_idx]\n","    y_val = y[val_idx]\n","\n","    train_user_ids = [user_ids_list[i] for i in train_idx]\n","    val_user_ids = [user_ids_list[i] for i in val_idx]\n","\n","    break"],"id":"626638afb300d137","outputs":[],"execution_count":null},{"metadata":{"id":"76fef52d5dd2f029"},"cell_type":"code","source":["class InteractionDataset(Dataset):\n","    def __init__(self, X, y, user_ids, user_features, item_features, user_id_map, item_id_map, item_encoder):\n","        self.X = X\n","        self.y = y\n","        self.user_ids = user_ids\n","        self.user_features = user_features\n","        self.item_features = item_features\n","        self.user_id_map = user_id_map\n","        self.item_id_map = item_id_map\n","        self.item_encoder = item_encoder\n","\n","    def __len__(self):\n","        return self.X.size(0)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.X[idx]\n","        target = self.y[idx]\n","\n","        user_id = self.user_ids[idx]\n","        user_idx = self.user_id_map.get(user_id, -1)\n","        if user_idx == -1 or user_idx >= self.user_features.size(0):\n","            user_feature = torch.zeros(self.user_features.size(1))\n","        else:\n","            user_feature = self.user_features[user_idx]\n","\n","        try:\n","            item_id = self.item_encoder.inverse_transform([target.item() - 1])[0]\n","        except ValueError:\n","            item_id = self.item_encoder.classes_[0]\n","\n","        item_idx = self.item_id_map.get(item_id, -1)\n","        if item_idx == -1 or item_idx >= self.item_features.size(0):\n","            item_feature = torch.zeros(self.item_features.size(1))\n","        else:\n","            item_feature = self.item_features[item_idx]\n","\n","        return sequence, target, user_feature, item_feature\n"],"id":"76fef52d5dd2f029","outputs":[],"execution_count":null},{"metadata":{"id":"c02a7b5d64f615d1"},"cell_type":"code","source":["train_dataset = InteractionDataset(\n","    X_train,\n","    y_train,\n","    train_user_ids,\n","    user_features_tensor,\n","    item_features_tensor,\n","    user_id_map,\n","    item_id_map,\n","    item_encoder\n",")\n","\n","val_dataset = InteractionDataset(\n","    X_val,\n","    y_val,\n","    val_user_ids,\n","    user_features_tensor,\n","    item_features_tensor,\n","    user_id_map,\n","    item_id_map,\n","    item_encoder\n",")\n"],"id":"c02a7b5d64f615d1","outputs":[],"execution_count":null},{"metadata":{"id":"83c603ca02b1661c"},"cell_type":"code","source":["batch_size = 256\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"],"id":"83c603ca02b1661c","outputs":[],"execution_count":null},{"metadata":{"id":"868818f44ffc4719"},"cell_type":"code","source":["class Seq2SeqRecommender(nn.Module):\n","    def __init__(self, num_items, embedding_dim, hidden_dim, user_feature_dim, item_feature_dim, padding_idx=0):\n","        super(Seq2SeqRecommender, self).__init__()\n","        self.embedding = nn.Embedding(num_items, embedding_dim, padding_idx=padding_idx)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","\n","        self.user_fc = nn.Linear(user_feature_dim, hidden_dim)\n","        self.item_fc = nn.Linear(item_feature_dim, hidden_dim)\n","\n","        self.fc = nn.Linear(hidden_dim * 2, num_items)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, sequences, user_features, item_features):\n","        embedded = self.embedding(sequences)\n","        lstm_out, (h_n, c_n) = self.lstm(embedded)\n","        user_emb = h_n.squeeze(0)\n","\n","        user_emb = self.user_fc(user_features)\n","        item_emb = self.item_fc(item_features)\n","\n","        combined = torch.cat([user_emb, item_emb], dim=1)\n","        combined = self.dropout(combined)\n","        logits = self.fc(combined)\n","\n","        return logits  # Без активации"],"id":"868818f44ffc4719","outputs":[],"execution_count":null},{"metadata":{"id":"40c057c15c043445"},"cell_type":"code","source":["\n","embedding_dim = 100\n","hidden_dim = 128\n","user_feature_dim = user_features_tensor.shape[1]\n","item_feature_dim = item_features_tensor.shape[1]\n","\n","\n","model = Seq2SeqRecommender(\n","    num_items=num_items,\n","    embedding_dim=embedding_dim,\n","    hidden_dim=hidden_dim,\n","    user_feature_dim=user_feature_dim,\n","    item_feature_dim=item_feature_dim,\n","    padding_idx=0\n",")\n"],"id":"40c057c15c043445","outputs":[],"execution_count":null},{"metadata":{"id":"caa3ed83a8833812"},"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, verbose=False, delta=0.0, path='checkpoint.pt'):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        \"\"\"Сохраняет модель, когда происходит улучшение.\"\"\"\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss\n","\n","early_stopping = EarlyStopping(patience=5, verbose=True)"],"id":"caa3ed83a8833812","outputs":[],"execution_count":null},{"metadata":{"id":"b7476433aa369ae9"},"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"id":"b7476433aa369ae9","outputs":[],"execution_count":null},{"metadata":{"id":"41250ce46bbda282"},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","\n","\n","scaler_amp = GradScaler()\n","\n","\n","num_epochs = 3\n","train_losses = []\n","val_losses = []\n","val_accuracies = []"],"id":"41250ce46bbda282","outputs":[],"execution_count":null},{"metadata":{"id":"abac319a111ccfe2"},"cell_type":"code","source":["from torch.amp import GradScaler, autocast\n","\n","scaler_amp = GradScaler()\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, targets, user_feats, item_feats in train_loader:\n","        sequences = sequences.to(device)\n","        targets = targets.to(device) - 1\n","        user_feats = user_feats.to(device)\n","        item_feats = item_feats.to(device)\n","\n","        optimizer.zero_grad()\n","\n","    with autocast(device_type='cuda'):\n","        logits = model(sequences, user_feats, item_feats)\n","        loss = criterion(logits, targets)\n","\n","\n","        scaler_amp.scale(loss).backward()\n","        scaler_amp.step(optimizer)\n","        scaler_amp.update()\n","\n","        running_loss += loss.item() * sequences.size(0)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    train_losses.append(epoch_loss)\n","\n","    model.eval()\n","    val_running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_targets = []\n","    all_preds = []\n","    all_probs = []\n","    with torch.no_grad():\n","        for sequences, targets, user_feats, item_feats in val_loader:\n","            sequences = sequences.to(device)\n","            targets = targets.to(device) - 1\n","            user_feats = user_feats.to(device)\n","            item_feats = item_feats.to(device)\n","\n","            with autocast():\n","                logits = model(sequences, user_feats, item_feats)  # [batch_size, num_items]\n","                loss = criterion(logits, targets)\n","\n","            val_running_loss += loss.item() * sequences.size(0)\n","\n","            probs = torch.softmax(logits, dim=1)  # [batch_size, num_items]\n","            preds = torch.argmax(probs, dim=1)   # [batch_size]\n","            correct += (preds == targets).sum().item()\n","            total += targets.size(0)\n","\n","            all_targets.extend(targets.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","            all_probs.extend(probs.cpu().numpy())\n","\n","    val_epoch_loss = val_running_loss / len(val_loader.dataset)\n","    val_losses.append(val_epoch_loss)\n","    val_accuracy = correct / total\n","    val_accuracies.append(val_accuracy)\n","\n","    precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0)\n","    recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0)\n","    f1 = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n","    try:\n","        auc = roc_auc_score(pd.get_dummies(all_targets), all_probs, average='weighted', multi_class='ovr')\n","    except ValueError:\n","        auc = 0.0  # Если невозможно вычислить AUC\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.6f}, Val Loss: {val_epoch_loss:.6f}, Val Acc: {val_accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC-AUC: {auc:.4f}')\n","\n","    # Проверка раннего остановка\n","    early_stopping(val_epoch_loss, model)\n","\n","    if early_stopping.early_stop:\n","        print(\"Раннее остановка активирована.\")\n","        break\n"],"id":"abac319a111ccfe2","outputs":[],"execution_count":null},{"metadata":{"id":"c9da561dea5615e1"},"cell_type":"code","source":["model.load_state_dict(torch.load('checkpoint.pt'))"],"id":"c9da561dea5615e1","outputs":[],"execution_count":null},{"metadata":{"id":"d9ebbc3c44bd173d"},"cell_type":"code","source":["train_user_set = set(train_user_ids)\n","val_user_set = set(val_user_ids)\n","overlap = train_user_set.intersection(val_user_set)\n","print(f'Количество перекрывающихся пользователей: {len(overlap)}')"],"id":"d9ebbc3c44bd173d","outputs":[],"execution_count":null},{"metadata":{"id":"ac41b11cea9ec3f1"},"cell_type":"code","source":["train_item_set = set(events_sorted.iloc[train_idx]['item_id'].unique())\n","val_item_set = set(events_sorted.iloc[val_idx]['item_id'].unique())\n","overlap_items = train_item_set.intersection(val_item_set)\n","print(f'Количество перекрывающихся элементов: {len(overlap_items)}')"],"id":"ac41b11cea9ec3f1","outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}